{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3De35MBUes-C"
      },
      "source": [
        "# Implementing ConvNext in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3i7w2nrdy9k"
      },
      "source": [
        "### Starting point: ResNet\n",
        "\n",
        "### DataSet - CIFAR-10\n",
        "\n",
        "(Initial dataset: ResNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-4gEWFcFjqf"
      },
      "source": [
        "# ResNet with all the stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1Dwvc5-EoGy"
      },
      "outputs": [],
      "source": [
        "# function for model training\n",
        "\n",
        "from TrainModel import train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from typing import List\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from torchvision.ops import StochasticDepth\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frw8k2WE-WER"
      },
      "outputs": [],
      "source": [
        "class ConvNormAct(nn.Sequential):\n",
        "  '''This class defines a sequence of operations: convolution, normalization, and activation.'''\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        kernel_size: int,\n",
        "        norm = nn.BatchNorm2d,\n",
        "        act = nn.ReLU,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            nn.Conv2d(\n",
        "                in_features,\n",
        "                out_features,\n",
        "                kernel_size=kernel_size,\n",
        "                padding=kernel_size // 2,\n",
        "                **kwargs\n",
        "            ),\n",
        "            norm(out_features),\n",
        "            act(),\n",
        "        )\n",
        "\n",
        "class BottleNeckBlock(nn.Module):\n",
        "  '''Purpose:\n",
        "        This class defines a bottleneck block, a common building block in ResNet architectures.\n",
        "      -----\n",
        "\n",
        "      Parameters:\n",
        "        in_features:\n",
        "            Number of input channels.\n",
        "        out_features:\n",
        "            Number of output channels.\n",
        "        reduction:\n",
        "            Reduction factor for the bottleneck block.\n",
        "        stride:\n",
        "            Stride for the first convolutional layer.\n",
        "\n",
        "       ------\n",
        "\n",
        "      Operation:\n",
        "        First convolutional layer:\n",
        "          Reduces input channels to reduced_features using a 1x1 kernel.\n",
        "        Second convolutional layer:\n",
        "          Applies 3x3 convolution to reduced_features.\n",
        "        Third convolutional layer:\n",
        "          Expands back to out_features using a 1x1 kernel and no activation function (nn.Identity()).\n",
        "        Shortcut connection:\n",
        "          Performs a 1x1 convolution on the input if the number of input and output channels differ, otherwise, it is an identity connection.\n",
        "        ReLU activation is applied.\n",
        "        '''\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        reduction: int = 4,\n",
        "        stride: int = 1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        reduced_features = out_features // reduction\n",
        "        self.block = nn.Sequential(\n",
        "            ConvNormAct(\n",
        "                in_features, reduced_features, kernel_size=1, stride=stride, bias=False\n",
        "            ),\n",
        "            ConvNormAct(reduced_features, reduced_features, kernel_size=3, bias=False),\n",
        "            ConvNormAct(reduced_features, out_features, kernel_size=1, bias=False, act=nn.Identity),\n",
        "        )\n",
        "        self.shortcut = (\n",
        "            nn.Sequential(\n",
        "                ConvNormAct(\n",
        "                    in_features, out_features, kernel_size=1, stride=stride, bias=False\n",
        "                )\n",
        "            )\n",
        "            if in_features != out_features\n",
        "            else nn.Identity()\n",
        "        )\n",
        "\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        res = x\n",
        "        x = self.block(x)\n",
        "        res = self.shortcut(res)\n",
        "        x += res\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "class ConvNexStage(nn.Sequential):\n",
        "    '''Purpose:\n",
        "            This class defines a stage of the ResNet architecture, composed of multiple bottleneck blocks.\n",
        "\n",
        "        Parameters:\n",
        "          in_features:\n",
        "              Number of input channels.\n",
        "          out_features:\n",
        "              Number of output channels.\n",
        "          depth:\n",
        "              Number of bottleneck blocks in the stage.\n",
        "          stride:\n",
        "              Stride for the first bottleneck block.\n",
        "\n",
        "        Operation:\n",
        "          First bottleneck block: Applies with the specified stride.\n",
        "          Subsequent bottleneck blocks: Each applies with a stride of 1.\n",
        "          The stage consists of a sequence of bottleneck blocks.\n",
        "        '''\n",
        "    def __init__(\n",
        "        self, in_features: int, out_features: int, depth: int, stride: int = 2, **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            BottleNeckBlock(in_features, out_features, stride=stride, **kwargs),\n",
        "            *[\n",
        "                BottleNeckBlock(out_features, out_features, **kwargs)\n",
        "                for _ in range(depth - 1)\n",
        "            ],\n",
        "        )\n",
        "\n",
        "class ConvNextStem(nn.Sequential):\n",
        "    '''Purpose:\n",
        "          This class defines the stem of the ResNet architecture, responsible for the initial transformation of input features.\n",
        "      Parameters:\n",
        "          in_features:\n",
        "              Number of input channels.\n",
        "          out_features:\n",
        "              Number of output channels.\n",
        "      Operation:\n",
        "          Applies a convolutional layer followed by normalization and activation.'''\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        super().__init__(\n",
        "            ConvNormAct(\n",
        "                in_features, out_features, kernel_size=3, stride=1  # Adjust kernel_size and stride\n",
        "            ),\n",
        "        )\n",
        "\n",
        "class ConvNextEncoder(nn.Module):\n",
        "  '''Purpose:\n",
        "        This class defines the complete ResNet-like encoder architecture.\n",
        "      Parameters:\n",
        "          in_channels: Number of input channels.\n",
        "          stem_features: Number of features after the stem.\n",
        "          depths: List specifying the number of bottleneck blocks in each stage.\n",
        "          widths: List specifying the number of output channels for each stage.\n",
        "          num_classes: Number of output classes (default is 10 for CIFAR-10).\n",
        "      Operation:\n",
        "          Stem: Applies initial transformations to input features.\n",
        "          Stages: A series of ConvNexStages, each consisting of multiple bottleneck blocks.\n",
        "          Global Average Pooling (GAP): Reduces spatial dimensions to 1x1.\n",
        "          Fully Connected Layer: Produces final output predictions.\n",
        "      '''\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        stem_features: int,\n",
        "        depths: List[int],\n",
        "        widths: List[int],\n",
        "        num_classes: int = 10  # Adjust for CIFAR-10\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.stem = ConvNextStem(in_channels, stem_features)\n",
        "\n",
        "        in_out_widths = list(zip(widths, widths[1:]))\n",
        "\n",
        "        self.stages = nn.ModuleList(\n",
        "            [\n",
        "                ConvNexStage(stem_features, widths[0], depths[0], stride=1),\n",
        "                *[\n",
        "                    ConvNexStage(in_features, out_features, depth)\n",
        "                    for (in_features, out_features), depth in zip(\n",
        "                        in_out_widths, depths[1:]\n",
        "                    )\n",
        "                ],\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Global Average Pooling (GAP)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(widths[-1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        for stage in self.stages:\n",
        "            x = stage(x)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully Connected Layer\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVd9klI3_DnL",
        "outputId": "f40256f3-392b-406d-d135-5160faacf667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Training: 100%|██████████| 782/782 [02:51<00:00,  4.55it/s]\n",
            "Epoch 1/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 14.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Training Loss: 1.9989, Training Accuracy: 29.87%, Validation Loss: 3.2034, Validation Accuracy: 42.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 - Training: 100%|██████████| 782/782 [02:49<00:00,  4.61it/s]\n",
            "Epoch 2/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Training Loss: 1.3789, Training Accuracy: 49.87%, Validation Loss: 1.2811, Validation Accuracy: 54.16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 - Training: 100%|██████████| 782/782 [02:49<00:00,  4.61it/s]\n",
            "Epoch 3/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Training Loss: 1.0901, Training Accuracy: 61.06%, Validation Loss: 1.2147, Validation Accuracy: 61.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 - Training: 100%|██████████| 782/782 [02:49<00:00,  4.61it/s]\n",
            "Epoch 4/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Training Loss: 0.8953, Training Accuracy: 68.35%, Validation Loss: 0.8347, Validation Accuracy: 70.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 - Training: 100%|██████████| 782/782 [02:48<00:00,  4.64it/s]\n",
            "Epoch 5/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Training Loss: 0.7537, Training Accuracy: 73.47%, Validation Loss: 0.7181, Validation Accuracy: 75.55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 - Training: 100%|██████████| 782/782 [02:47<00:00,  4.66it/s]\n",
            "Epoch 6/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Training Loss: 0.6448, Training Accuracy: 77.60%, Validation Loss: 0.7129, Validation Accuracy: 75.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 - Training: 100%|██████████| 782/782 [02:48<00:00,  4.64it/s]\n",
            "Epoch 7/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Training Loss: 0.5729, Training Accuracy: 80.16%, Validation Loss: 0.6304, Validation Accuracy: 79.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 - Training: 100%|██████████| 782/782 [02:49<00:00,  4.63it/s]\n",
            "Epoch 8/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Training Loss: 0.5168, Training Accuracy: 82.17%, Validation Loss: 0.5838, Validation Accuracy: 81.04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 - Training: 100%|██████████| 782/782 [02:48<00:00,  4.65it/s]\n",
            "Epoch 9/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Training Loss: 0.4631, Training Accuracy: 84.04%, Validation Loss: 0.4925, Validation Accuracy: 83.02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 - Training: 100%|██████████| 782/782 [02:47<00:00,  4.66it/s]\n",
            "Epoch 10/10 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Training Loss: 0.4259, Training Accuracy: 85.32%, Validation Loss: 0.6067, Validation Accuracy: 80.55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_1 = ConvNextEncoder(in_channels=3, stem_features=64, depths=[3, 4, 6, 4], widths=[256, 512, 1024, 2048], num_classes=10)\n",
        "optimizer_1 = optim.SGD(model_1.parameters(), lr=0.01, momentum=0.9)\n",
        "train_model(model_1, optimizer_1, num_epochs=10, learning_rate=0.01, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_t1NjMT3zCY"
      },
      "source": [
        "# ConvNeXt\n",
        "-----\n",
        "## Patchify + AdamW + Changing stage compute ratio\n",
        "-----\n",
        "### 1. Parchify\n",
        "\n",
        "- basically means that we increase kernel size and the kernel size is equal to stride\n",
        "\n",
        "### 2. AdamW started to be used when Transformers came to CV\n",
        "\n",
        "### 3. Changing stage compute ratio\n",
        "\n",
        "- For larger Swin Transformers, the ratio is 1:1:9:1. Following the design, we adjust the number of blocks in each stage from (3, 4, 6, 3) in ResNet-50 to (3, 3, 9, 3), which also aligns the FLOPs with Swin-T.\n",
        "\n",
        "---\n",
        "### Expectation:\n",
        "\n",
        "Accuracy increase by 2.7%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O7D90AikS3O"
      },
      "outputs": [],
      "source": [
        "class ConvNextStem(nn.Sequential):\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        super().__init__(\n",
        "            nn.Conv2d(in_features, out_features, kernel_size=4, stride=4),\n",
        "            nn.BatchNorm2d(out_features)\n",
        "        )\n",
        "\n",
        "# from now on\n",
        "LR = 0.005\n",
        "EPOCH = 20\n",
        "BATCH = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x3PdwOMdXhs",
        "outputId": "da0f569f-7f57-4987-8665-1f35812ead05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.66it/s]\n",
            "Epoch 1/20 - Validation: 100%|██████████| 157/157 [00:02<00:00, 52.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Training Loss: 2.6066, Training Accuracy: 16.72%, Validation Loss: 1.9899, Validation Accuracy: 21.72\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.82it/s]\n",
            "Epoch 2/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 50.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20, Training Loss: 1.9268, Training Accuracy: 25.13%, Validation Loss: 1.7953, Validation Accuracy: 30.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.75it/s]\n",
            "Epoch 3/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 51.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/20, Training Loss: 1.7057, Training Accuracy: 35.34%, Validation Loss: 1.6111, Validation Accuracy: 41.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20 - Training: 100%|██████████| 782/782 [00:48<00:00, 16.15it/s]\n",
            "Epoch 4/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 44.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/20, Training Loss: 1.5967, Training Accuracy: 40.44%, Validation Loss: 1.7732, Validation Accuracy: 35.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.93it/s]\n",
            "Epoch 5/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 40.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/20, Training Loss: 1.5606, Training Accuracy: 41.85%, Validation Loss: 1.4346, Validation Accuracy: 47.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.94it/s]\n",
            "Epoch 6/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 45.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/20, Training Loss: 1.4305, Training Accuracy: 47.52%, Validation Loss: 1.4856, Validation Accuracy: 46.07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20 - Training: 100%|██████████| 782/782 [00:48<00:00, 16.00it/s]\n",
            "Epoch 7/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 52.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/20, Training Loss: 1.4125, Training Accuracy: 48.42%, Validation Loss: 1.4159, Validation Accuracy: 49.87\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.85it/s]\n",
            "Epoch 8/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 49.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/20, Training Loss: 1.3154, Training Accuracy: 52.34%, Validation Loss: 1.3946, Validation Accuracy: 50.19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.77it/s]\n",
            "Epoch 9/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 50.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/20, Training Loss: 1.2238, Training Accuracy: 55.86%, Validation Loss: 1.2369, Validation Accuracy: 56.85\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.65it/s]\n",
            "Epoch 10/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 51.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/20, Training Loss: 1.1608, Training Accuracy: 58.31%, Validation Loss: 1.1455, Validation Accuracy: 60.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20 - Training: 100%|██████████| 782/782 [00:50<00:00, 15.41it/s]\n",
            "Epoch 11/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 51.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/20, Training Loss: 1.1067, Training Accuracy: 60.73%, Validation Loss: 1.1786, Validation Accuracy: 58.74\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.77it/s]\n",
            "Epoch 12/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 51.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/20, Training Loss: 1.0665, Training Accuracy: 62.22%, Validation Loss: 1.0440, Validation Accuracy: 62.82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.83it/s]\n",
            "Epoch 13/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 48.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/20, Training Loss: 1.0253, Training Accuracy: 63.79%, Validation Loss: 1.0837, Validation Accuracy: 61.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.91it/s]\n",
            "Epoch 14/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 44.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/20, Training Loss: 0.9823, Training Accuracy: 65.20%, Validation Loss: 0.9372, Validation Accuracy: 66.98\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20 - Training: 100%|██████████| 782/782 [00:48<00:00, 15.97it/s]\n",
            "Epoch 15/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 40.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/20, Training Loss: 0.9547, Training Accuracy: 66.32%, Validation Loss: 0.9350, Validation Accuracy: 67.77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20 - Training: 100%|██████████| 782/782 [00:48<00:00, 16.11it/s]\n",
            "Epoch 16/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 46.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/20, Training Loss: 0.9333, Training Accuracy: 67.01%, Validation Loss: 0.8544, Validation Accuracy: 70.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20 - Training: 100%|██████████| 782/782 [00:48<00:00, 16.02it/s]\n",
            "Epoch 17/20 - Validation: 100%|██████████| 157/157 [00:02<00:00, 52.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/20, Training Loss: 0.8722, Training Accuracy: 69.53%, Validation Loss: 0.8036, Validation Accuracy: 72.11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.88it/s]\n",
            "Epoch 18/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 51.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/20, Training Loss: 0.8432, Training Accuracy: 70.63%, Validation Loss: 0.8230, Validation Accuracy: 71.82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.89it/s]\n",
            "Epoch 19/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 51.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/20, Training Loss: 0.8373, Training Accuracy: 70.98%, Validation Loss: 0.8124, Validation Accuracy: 72.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20 - Training: 100%|██████████| 782/782 [00:49<00:00, 15.93it/s]\n",
            "Epoch 20/20 - Validation: 100%|██████████| 157/157 [00:03<00:00, 51.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/20, Training Loss: 0.7885, Training Accuracy: 72.50%, Validation Loss: 0.7729, Validation Accuracy: 73.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_2 = ConvNextEncoder(in_channels=3, stem_features=64, depths=[3,3,9,3], widths=[256, 512, 1024, 2048], num_classes=10)\n",
        "optimizer = optim.AdamW(model_2.parameters(), lr=LR)\n",
        "train_model(model_2, optimizer, num_epochs=EPOCH, learning_rate=LR, batch_size=BATCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssdbzKVU4TmQ"
      },
      "source": [
        "## ResNeXt-ify + Inverted Bottleneck\n",
        "-----\n",
        "\n",
        "### * ResNeXt-ify\n",
        "In ConvNext, they use depth-wise convolution (like in MobileNet and later in EfficientNet). Depth-wise convs are grouped convolutions where the number of groups is equal to the number of input channels.\n",
        "\n",
        "The authors notice that is very similar to the weighted sum operation in self-attention, which mixes information only in the spatial dimension. Using depth-wise convs reduce the accuracy (since we are not increasing the widths like in ResNetXt), this is expected.\n",
        "\n",
        "So we change our 3x3 conv inside BottleNeck block to\n",
        "\n",
        "```ConvNormAct(reduced_features, reduced_features, kernel_size=3, bias=False, groups=reduced_features)```\n",
        "\n",
        "### * Inverted Bottleneck\n",
        "\n",
        "Our BottleNeck first reduces the features via a 1x1 conv, then it applies the heavy 3x3 conv and finally expands the features to the original size. An inverted bottleneck block, does the opposite. I have a whole article with nice visualization about them.\n",
        "\n",
        "So we go from ```wide -> narrow -> wide``` to ```narrow -> wide -> narrow```\n",
        "\n",
        "This is similar to Transformers, since the MLP layer follows the narrow -> wide -> narrow design, the second dense layer in the MLP expands the input's feature by a factor of four.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PanSm0dNYise"
      },
      "outputs": [],
      "source": [
        "class BottleNeckBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        expansion: int = 4,\n",
        "        stride: int = 1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        expanded_features = out_features * expansion\n",
        "        self.block = nn.Sequential(\n",
        "            # narrow -> wide\n",
        "            ConvNormAct(\n",
        "                in_features, expanded_features, kernel_size=1, stride=stride, bias=False\n",
        "            ),\n",
        "            # wide -> wide (with depth-wise)\n",
        "            ConvNormAct(expanded_features, expanded_features, kernel_size=3, bias=False, groups=in_features), # groups refer to  ResNexT\n",
        "            # wide -> narrow\n",
        "            ConvNormAct(expanded_features, out_features, kernel_size=1, bias=False, act=nn.Identity),\n",
        "        )\n",
        "        self.shortcut = (\n",
        "            nn.Sequential(\n",
        "                ConvNormAct(\n",
        "                    in_features, out_features, kernel_size=1, stride=stride, bias=False\n",
        "                )\n",
        "            )\n",
        "            if in_features != out_features\n",
        "            else nn.Identity()\n",
        "        )\n",
        "\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        res = x\n",
        "        x = self.block(x)\n",
        "        res = self.shortcut(res)\n",
        "        x += res\n",
        "        x = self.act(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB9Dna0KPax-",
        "outputId": "308e42ef-c626-4758-9ccc-cb666255dc44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 36638959.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 - Training: 100%|██████████| 782/782 [04:18<00:00,  3.03it/s]\n",
            "Epoch 1/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Training Loss: 2.5493, Training Accuracy: 19.54%, Validation Loss: 2.0077, Validation Accuracy: 27.11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20 - Training: 100%|██████████| 782/782 [04:11<00:00,  3.11it/s]\n",
            "Epoch 2/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20, Training Loss: 1.8892, Training Accuracy: 29.38%, Validation Loss: 1.7289, Validation Accuracy: 36.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20 - Training: 100%|██████████| 782/782 [04:12<00:00,  3.10it/s]\n",
            "Epoch 3/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/20, Training Loss: 1.8473, Training Accuracy: 30.11%, Validation Loss: 1.6320, Validation Accuracy: 38.07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20 - Training: 100%|██████████| 782/782 [04:12<00:00,  3.10it/s]\n",
            "Epoch 4/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/20, Training Loss: 1.5876, Training Accuracy: 40.70%, Validation Loss: 1.4603, Validation Accuracy: 45.97\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20 - Training: 100%|██████████| 782/782 [04:12<00:00,  3.10it/s]\n",
            "Epoch 5/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/20, Training Loss: 1.4047, Training Accuracy: 48.44%, Validation Loss: 1.3657, Validation Accuracy: 50.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20 - Training: 100%|██████████| 782/782 [04:11<00:00,  3.11it/s]\n",
            "Epoch 6/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/20, Training Loss: 1.2575, Training Accuracy: 54.76%, Validation Loss: 1.5803, Validation Accuracy: 51.23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20 - Training: 100%|██████████| 782/782 [04:11<00:00,  3.11it/s]\n",
            "Epoch 7/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/20, Training Loss: 1.1299, Training Accuracy: 59.70%, Validation Loss: 1.0024, Validation Accuracy: 64.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20 - Training: 100%|██████████| 782/782 [04:11<00:00,  3.11it/s]\n",
            "Epoch 8/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/20, Training Loss: 1.0309, Training Accuracy: 63.45%, Validation Loss: 1.1143, Validation Accuracy: 61.65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20 - Training: 100%|██████████| 782/782 [04:11<00:00,  3.11it/s]\n",
            "Epoch 9/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/20, Training Loss: 0.9724, Training Accuracy: 65.93%, Validation Loss: 0.9546, Validation Accuracy: 67.87\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20 - Training: 100%|██████████| 782/782 [04:11<00:00,  3.11it/s]\n",
            "Epoch 10/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/20, Training Loss: 0.8911, Training Accuracy: 69.00%, Validation Loss: 0.8089, Validation Accuracy: 71.92\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20 - Training: 100%|██████████| 782/782 [04:11<00:00,  3.11it/s]\n",
            "Epoch 11/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/20, Training Loss: 0.8593, Training Accuracy: 70.03%, Validation Loss: 0.7814, Validation Accuracy: 73.16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20 - Training: 100%|██████████| 782/782 [04:10<00:00,  3.12it/s]\n",
            "Epoch 12/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/20, Training Loss: 0.7625, Training Accuracy: 73.72%, Validation Loss: 0.7584, Validation Accuracy: 74.08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20 - Training: 100%|██████████| 782/782 [04:10<00:00,  3.12it/s]\n",
            "Epoch 13/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/20, Training Loss: 0.7211, Training Accuracy: 75.17%, Validation Loss: 0.6958, Validation Accuracy: 76.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20 - Training: 100%|██████████| 782/782 [04:10<00:00,  3.12it/s]\n",
            "Epoch 14/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/20, Training Loss: 0.6946, Training Accuracy: 76.10%, Validation Loss: 0.6861, Validation Accuracy: 76.28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20 - Training: 100%|██████████| 782/782 [04:10<00:00,  3.12it/s]\n",
            "Epoch 15/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/20, Training Loss: 0.6608, Training Accuracy: 77.33%, Validation Loss: 0.6710, Validation Accuracy: 77.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20 - Training: 100%|██████████| 782/782 [04:10<00:00,  3.13it/s]\n",
            "Epoch 16/20 - Validation: 100%|██████████| 157/157 [00:19<00:00,  7.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/20, Training Loss: 0.6606, Training Accuracy: 77.49%, Validation Loss: 0.6319, Validation Accuracy: 78.34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20 - Training: 100%|██████████| 782/782 [04:10<00:00,  3.13it/s]\n",
            "Epoch 17/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/20, Training Loss: 0.6335, Training Accuracy: 78.25%, Validation Loss: 0.6663, Validation Accuracy: 77.83\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20 - Training: 100%|██████████| 782/782 [04:09<00:00,  3.13it/s]\n",
            "Epoch 18/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/20, Training Loss: 0.5949, Training Accuracy: 79.90%, Validation Loss: 3.0171, Validation Accuracy: 69.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20 - Training: 100%|██████████| 782/782 [04:09<00:00,  3.14it/s]\n",
            "Epoch 19/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/20, Training Loss: 0.5943, Training Accuracy: 79.66%, Validation Loss: 0.6413, Validation Accuracy: 78.24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20 - Training: 100%|██████████| 782/782 [04:09<00:00,  3.13it/s]\n",
            "Epoch 20/20 - Validation: 100%|██████████| 157/157 [00:20<00:00,  7.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/20, Training Loss: 0.5432, Training Accuracy: 81.32%, Validation Loss: 0.5725, Validation Accuracy: 80.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_3 = ConvNextEncoder(in_channels=3, stem_features=64, depths=[3,3,9,3], widths=[256, 512, 1024, 2048], num_classes=10)\n",
        "optimizer = optim.AdamW(model_3.parameters(), lr=LR)\n",
        "train_model(model_3, optimizer, num_epochs=EPOCH, learning_rate=LR, batch_size=BATCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx8c-yTm7MSd"
      },
      "source": [
        "## Large Kernel Sizes\n",
        "-------\n",
        "\n",
        "Modern Vision Transfomer, like Swin, uses a bigger kernel size (7x7). Increasing the kernel size will make the computation more expensive, so we move up the big depth-wise conv, by doing so we will have fewer channels. The authors note this is similar to Transformers model where the Multihead Self Attention (MSA) is done before the MLP layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHJO8Soj7dRX"
      },
      "outputs": [],
      "source": [
        "# on VM\n",
        "# best score is\n",
        "# colab crahes\n",
        "# Epoch 19/20, Training Loss: 0.5628, Training Accuracy: 80.58%, Validation Loss: 0.6100, Validation Accuracy: 78.99\n",
        "\n",
        "class BottleNeckBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        expansion: int = 4,\n",
        "        stride: int = 1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        expanded_features = out_features * expansion\n",
        "        self.block = nn.Sequential(\n",
        "            # narrow -> wide (with depth-wise and bigger kernel)\n",
        "            ConvNormAct(\n",
        "                in_features, in_features, kernel_size=7, stride=stride, bias=False, groups=in_features\n",
        "            ),\n",
        "            # wide -> wide\n",
        "            ConvNormAct(in_features, expanded_features, kernel_size=1),\n",
        "            # wide -> narrow\n",
        "            ConvNormAct(expanded_features, out_features, kernel_size=1, bias=False, act=nn.Identity),\n",
        "        )\n",
        "        self.shortcut = (\n",
        "            nn.Sequential(\n",
        "                ConvNormAct(\n",
        "                    in_features, out_features, kernel_size=1, stride=stride, bias=False\n",
        "                )\n",
        "            )\n",
        "            if in_features != out_features\n",
        "            else nn.Identity()\n",
        "        )\n",
        "\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        res = x\n",
        "        x = self.block(x)\n",
        "        res = self.shortcut(res)\n",
        "        x += res\n",
        "        x = self.act(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax5rN3c9SXkq"
      },
      "outputs": [],
      "source": [
        "model_4 = ConvNextEncoder(in_channels=3, stem_features=64, depths=[3,3,9,3], widths=[256, 512, 1024, 2048], num_classes=10)\n",
        "optimizer = optim.AdamW(model_3.parameters(), lr=LR)\n",
        "train_model(model_4, optimizer, num_epochs=EPOCH, learning_rate=LR, batch_size=BATCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsPj1TBF7pA_",
        "outputId": "02ba8e55-59af-4c75-b8a3-4faf96b3536b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/20, Training Loss: 0.5628, Training Accuracy: 80.58%, Validation Loss: 0.6100, Validation Accuracy: 78.99\n"
          ]
        }
      ],
      "source": [
        "print('Epoch 19/20, Training Loss: 0.5628, Training Accuracy: 80.58%, Validation Loss: 0.6100, Validation Accuracy: 78.99')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdzY7plh8DYv"
      },
      "source": [
        "# Micro Design\n",
        "----\n",
        "##Replacing ReLU with GELU\n",
        "\n",
        "- Since GELU is used by the most advanced transformers, why not use it in our model? The authors report the accuracy stays unchanged. In PyTorch GELU in nn.GELU.\n",
        "\n",
        "## Fewer activation functions\n",
        "\n",
        "- Our block has three activation functions. While, in Transformer block, there is only one activation function, the one inside the MLP block. The authors removed all the activations except for the one after the middle conv layer. This improves accuracy to 81.3% matching Swin-T!\n",
        "\n",
        "## Fewer normalization layers\n",
        "\n",
        "- Similar to activations, Transformers blocks have fewer normalization layers. The authors decide the remove all the BatchNorm and kept only the one before the middle conv.\n",
        "\n",
        "## Substituting BN with LN\n",
        "\n",
        "- Well, they substitute the BatchNorm layers with LinearyNorm. They note that doing so in the original ResNet hurts performance, but after all our changes, the performance increases to 81.5%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09OJdpEdZU2n"
      },
      "source": [
        "## Separate downsampling layers.\n",
        "\n",
        "- In ResNet the downsampling is done by the stride=2 conv.\n",
        "\n",
        "- Transformers (and other conv nets too) have a separate downsampling block.\n",
        "\n",
        "- The authors removed the stride=2 and add a downsampling block before the three convs using a 2x2 stride=2 conv. Normalization is needed before the downsampling operation to maintain stability during training.\n",
        "\n",
        "We can add this module to our ConvNexStage.\n",
        "\n",
        "\n",
        "## Stochastic Depth, also known as Drop Path, and Layer Scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfcrmMO1AzOK",
        "outputId": "c07d2e23-dba8-4178-c338-919e2a695b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 45206921.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50: 100%|██████████| 782/782 [02:26<00:00,  5.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Validation Accuracy: 35.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/50, Validation Accuracy: 42.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/50, Validation Accuracy: 43.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/50, Validation Accuracy: 48.58%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/50, Validation Accuracy: 50.19%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/50, Validation Accuracy: 52.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/50, Validation Accuracy: 53.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/50, Validation Accuracy: 53.33%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/50, Validation Accuracy: 55.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/50, Validation Accuracy: 54.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/50, Validation Accuracy: 57.45%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/50, Validation Accuracy: 58.25%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/50, Validation Accuracy: 57.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/50, Validation Accuracy: 59.21%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/50, Validation Accuracy: 60.41%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/50, Validation Accuracy: 60.13%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/50, Validation Accuracy: 60.69%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/50, Validation Accuracy: 60.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/50, Validation Accuracy: 60.97%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/50, Validation Accuracy: 61.57%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/50, Validation Accuracy: 63.04%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/50, Validation Accuracy: 62.33%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/50, Validation Accuracy: 63.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/50, Validation Accuracy: 63.70%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/50, Validation Accuracy: 63.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/50, Validation Accuracy: 64.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/50, Validation Accuracy: 63.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/50: 100%|██████████| 782/782 [02:22<00:00,  5.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/50, Validation Accuracy: 63.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/50, Validation Accuracy: 64.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/50, Validation Accuracy: 65.52%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/50: 100%|██████████| 782/782 [02:22<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/50, Validation Accuracy: 64.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/50:   3%|▎         | 21/782 [00:03<02:18,  5.48it/s]"
          ]
        }
      ],
      "source": [
        "BATCH = 64\n",
        "\n",
        "class ConvNormAct(nn.Sequential):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        kernel_size: int,\n",
        "        norm = nn.BatchNorm2d,\n",
        "        act = nn.ReLU,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            nn.Conv2d(\n",
        "                in_features,\n",
        "                out_features,\n",
        "                kernel_size=kernel_size,\n",
        "                padding=kernel_size // 2,\n",
        "                **kwargs\n",
        "            ),\n",
        "            norm(out_features),\n",
        "            act(),\n",
        "        )\n",
        "\n",
        "\n",
        "#####################\n",
        "\n",
        "class BottleNeckBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        expansion: int = 4,\n",
        "        drop_p: float = .0,\n",
        "        layer_scaler_init_value: float = 1e-6,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        expanded_features = out_features * expansion\n",
        "        self.block = nn.Sequential(\n",
        "            # narrow -> wide (with depth-wise and bigger kernel)\n",
        "            nn.Conv2d(\n",
        "                in_features, in_features, kernel_size=7, padding=3, bias=False, groups=in_features\n",
        "            ),\n",
        "            # GroupNorm with num_groups=1 is the same as LayerNorm but works for 2D data\n",
        "            nn.GroupNorm(num_groups=1, num_channels=in_features),\n",
        "            # wide -> wide\n",
        "            nn.Conv2d(in_features, expanded_features, kernel_size=1),\n",
        "            nn.GELU(),\n",
        "            # wide -> narrow\n",
        "            nn.Conv2d(expanded_features, out_features, kernel_size=1),\n",
        "        )\n",
        "        self.layer_scaler = LayerScaler(layer_scaler_init_value, out_features)\n",
        "        self.drop_path = StochasticDepth(drop_p, mode=\"batch\")\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        res = x\n",
        "        x = self.block(x)\n",
        "        x = self.layer_scaler(x)\n",
        "        x = self.drop_path(x)\n",
        "        x += res\n",
        "        return x\n",
        "\n",
        "#################\n",
        "\n",
        "class ConvNexStage(nn.Sequential):\n",
        "    def __init__(\n",
        "        self, in_features: int, out_features: int, depth: int, **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            # add the downsampler\n",
        "            nn.Sequential(\n",
        "                nn.GroupNorm(num_groups=1, num_channels=in_features),\n",
        "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1)\n",
        "            ),\n",
        "            *[\n",
        "                BottleNeckBlock(out_features, out_features, **kwargs)\n",
        "                for _ in range(depth)\n",
        "            ],\n",
        "        )\n",
        "\n",
        "class ConvNextStem(nn.Sequential):\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        super().__init__(\n",
        "            nn.Conv2d(in_features, out_features, kernel_size=4, stride=4),\n",
        "            nn.BatchNorm2d(out_features)\n",
        "        )\n",
        "\n",
        "\n",
        "class LayerScaler(nn.Module):\n",
        "    def __init__(self, init_value: float, dimensions: int):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Parameter(init_value * torch.ones((dimensions)),\n",
        "                                    requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gamma[None,...,None,None] * x\n",
        "\n",
        "class ConvNextEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        stem_features: int,\n",
        "        depths: List[int],\n",
        "        widths: List[int],\n",
        "        drop_p: float = .0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.stem = ConvNextStem(in_channels, stem_features)\n",
        "\n",
        "        in_out_widths = list(zip(widths, widths[1:]))\n",
        "        # create drop paths probabilities (one for each stage)\n",
        "        drop_probs = [x.item() for x in torch.linspace(0, drop_p, sum(depths))]\n",
        "\n",
        "        self.stages = nn.ModuleList(\n",
        "            [\n",
        "                ConvNexStage(stem_features, widths[0], depths[0], drop_p=drop_probs[0]),\n",
        "                *[\n",
        "                    ConvNexStage(in_features, out_features, depth, drop_p=drop_p)\n",
        "                    for (in_features, out_features), depth, drop_p in zip(\n",
        "                        in_out_widths, depths[1:], drop_probs[1:]\n",
        "                    )\n",
        "                ],\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        for stage in self.stages:\n",
        "            x = stage(x)\n",
        "        return x\n",
        "\n",
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, num_channels: int, num_classes: int = 10):\n",
        "        super().__init__(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(1),\n",
        "            nn.LayerNorm(num_channels),\n",
        "            nn.Linear(num_channels, num_classes)\n",
        "        )\n",
        "\n",
        "class ConvNextForImageClassification(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 stem_features: int,\n",
        "                 depths: List[int],\n",
        "                 widths: List[int],\n",
        "                 drop_p: float = .0,\n",
        "                 num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        self.encoder = ConvNextEncoder(in_channels, stem_features, depths, widths, drop_p)\n",
        "        self.head = ClassificationHead(widths[-1], num_classes)\n",
        "\n",
        "\n",
        "# CIFAR-10 Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH, shuffle=False)\n",
        "\n",
        "# Create the model\n",
        "model = ConvNextForImageClassification(in_channels=3, stem_features=64, depths=[3, 3, 9, 3], widths=[256, 512, 1024, 2048], num_classes=10)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
        "        # Move inputs and targets to the GPU\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, targets in test_loader:\n",
        "            # Move inputs and targets to the GPU\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {accuracy * 100:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP6B9Fh92jI9"
      },
      "source": [
        "## SWIN transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_pN5n3feool",
        "outputId": "65ff6e40-39a6-4524-de36-bb4c30c8e9d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SwinTransformer(\n",
            "  (stem): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
            "  (blocks): Sequential(\n",
            "    (0): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (1): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (2): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (3): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (4): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (5): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (6): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (7): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (8): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (9): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (10): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "    (11): SwinBlock(\n",
            "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (global_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
            "  (fc): Linear(in_features=96, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SwinBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
        "        super(SwinBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=kernel_size // 2)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, 1, padding=kernel_size // 2)\n",
        "        self.norm = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "class SwinTransformer(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=10, embed_dim=96, num_blocks=[2, 2, 6, 2], window_size=7):\n",
        "        super(SwinTransformer, self).__init__()\n",
        "\n",
        "        self.stem = nn.Conv2d(in_channels, embed_dim, kernel_size=window_size, stride=4, padding=window_size // 2)\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(num_blocks)):\n",
        "            num_blocks_i = num_blocks[i]\n",
        "            stride = 2 if i != 0 else 1\n",
        "            for _ in range(num_blocks_i):\n",
        "                layers.append(SwinBlock(embed_dim, embed_dim, stride=stride))\n",
        "                stride = 1\n",
        "\n",
        "        self.blocks = nn.Sequential(*layers)\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "model = SwinTransformer()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuG_17j8COKq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
